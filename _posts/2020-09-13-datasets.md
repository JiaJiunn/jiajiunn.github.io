---
title: Utilizing Tensorflow and Pytorch Torchvision Datasets
date: 2020-09-13 00:20:00 -0400
categories: []
tags: [datasets]     # TAG names should always be lowercase
---

An integral component of any high-performing model is the dataset; it defines the real world example that forms the basis of what a model learns. But for some, gathering a clean, well-formatted dataset while focusing on fine-tuning their network and learning parameters can be quite a daunting task; for this purpose, machine learning frameworks like Tensorflow and PyTorch offer built-in support for easily accessing some of the most common datasets. In this post, I thought it’d be nice to share some examples of utilizing the Tensorflow Dataset and PyTorch’s torchvision dataset, which I found useful whenever I wanted a quick start on my machine learning projects.

## Tensorflow Dataset

The full list of TensorFlow Datasets can be found [here](https://www.tensorflow.org/datasets/catalog/overview). As you can tell, the list is quite extensive; I personally am interested in implementing a panoptic segmentation network at the moment, so I decided to check out the COCO 2017 panoptic dataset. I first ran a few imports:

![tf imports](/assets/datasets/tf_imports.png)

and tried loading the dataset. For me, though, I got some errors for exceeding the limit allowed for open files. I solved this error by simply increasing the soft limit for number of open files on my device:

![tf file lim](/assets/datasets/tf_file_lim.png)

and now, I finally load in the dataset:

![tf load](/assets/datasets/tf_load.png)

To be clear, the parameter `download` should be set to `True` whenever calling this function for the first time. This downloads the COCO dataset onto your local machine, in whichever directory you define; by default it should be under `~/tensorflow_datasets/coco/2017_panoptic/1.1.0/`. I also set the `split` parameter above to `train[10:20]`, since I only wanted to download a portion of the dataset. For future function calls, you can simply set `download=False` for using the dataset already downloaded on your local machine.

Now that we have the dataset in our directory, we can load in our dataset it as an iterator. This allows for lazy evaluation of each sample of the dataset (rather than storing the entire thing in memory upon initiation), which makes it more memory efficient. Whenever we want a sample of the dataset, we can simply use the default iterator’s `get_next()` method:

![tf iter](/assets/datasets/tf_iter.png)

And finally, here's an image from our dataset!

![tf image](/assets/datasets/tf_image.png)

From the [documentation](https://www.tensorflow.org/datasets/catalog/coco) given on the Tensorflow COCO dataset, we can see that we have several labels we can get for each image. For instance, we can get the panoptic mask:

![tf mask](/assets/datasets/tf_mask.png)

as well as various ground truth labels such as bounding boxes and the corresponding classes:

![tf label](/assets/datasets/tf_label.png)

which can then be piped into a training or evaluation pipeline for further use.

## Torchvision Dataset

For proponents of PyTorch, the [torchvision](https://pytorch.org/docs/stable/torchvision/datasets.html) library also has in-built support for several popular datasets. In contrast to Tensorflow, though, the number of PyTorch-supported datasets are significantly lesser, and use cases much limited. Nevertheless, it still covers most of the popularly used datasets (it also includes COCO!) and is a good place to start for any machine learning projects in PyTorch.

For some variation, I thought I’d run through a set up for the MNIST dataset, which is really popular for introductory machine learning projects (can be easily trained with simpler models like LeNet). I started off by running the imports as usual:

![pt imports](/assets/datasets/pt_imports.png)

One important detail is that the images loaded from the MNIST dataset are PIL images. This itself isn’t a problem, but for using PyTorch’s data loader, the function expects a tensor as the image input. Hence while loading in the data below, I included a transform for converting each loaded PIL image into a tensor. Note that any other transforms (such as modifying the image size, or changing it to grayscale etc.) can be done by simply adding the transform into the list of `transforms.Compose`.

![pt download](/assets/datasets/pt_download.png)

As in the Tensorflow example, the parameter `download` should be set to `True` only when using the function for the first time, which downloads the dataset into whichever directory defined by `root`. For future calls, setting `download=False` will then simply get the dataset from the `root` directory.

Now, we again load in our dataset as an iterator:

![pt load](/assets/datasets/pt_load.png)

As before, we can get the next sample using the in-built `next()` method.

![pt iter](/assets/datasets/pt_iter.png)

And we are done! Here is a sample image and its corresponding ground truth label, 5:

![pt sample](/assets/datasets/pt_sample.png)

Hope you found this post helpful as a quick and easy start for your own machine learning projects!