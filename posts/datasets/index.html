<!DOCTYPE html><html lang="en" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Tensorflow and Pytorch Torchvision Datasets | Jia Jiunn Ang</title><meta name="generator" content="Jekyll v4.1.1" /><meta property="og:title" content="Tensorflow and Pytorch Torchvision Datasets" /><meta name="author" content="Jia Jiunn Ang" /><meta property="og:locale" content="en_US" /><meta name="description" content="An integral component of any high-performing model is the dataset; it defines the real world examples that form the basis of what a model learns. But for some, gathering a clean, well-formatted dataset while focusing on fine-tuning their network and learning parameters can be quite a daunting task; for this purpose, machine learning frameworks like Tensorflow and PyTorch offer built-in support for easily accessing some of the most common datasets. In this post, I thought it’d be nice to share some examples of utilizing the Tensorflow Dataset as well as PyTorch’s torchvision dataset, which I found useful whenever I wanted a quick start on my machine learning projects." /><meta property="og:description" content="An integral component of any high-performing model is the dataset; it defines the real world examples that form the basis of what a model learns. But for some, gathering a clean, well-formatted dataset while focusing on fine-tuning their network and learning parameters can be quite a daunting task; for this purpose, machine learning frameworks like Tensorflow and PyTorch offer built-in support for easily accessing some of the most common datasets. In this post, I thought it’d be nice to share some examples of utilizing the Tensorflow Dataset as well as PyTorch’s torchvision dataset, which I found useful whenever I wanted a quick start on my machine learning projects." /><link rel="canonical" href="https://jiajiunn.github.io/posts/datasets/" /><meta property="og:url" content="https://jiajiunn.github.io/posts/datasets/" /><meta property="og:site_name" content="Jia Jiunn Ang" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-09-13T00:20:00-04:00" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"headline":"Tensorflow and Pytorch Torchvision Datasets","dateModified":"2020-09-13T00:20:00-04:00","datePublished":"2020-09-13T00:20:00-04:00","description":"An integral component of any high-performing model is the dataset; it defines the real world examples that form the basis of what a model learns. But for some, gathering a clean, well-formatted dataset while focusing on fine-tuning their network and learning parameters can be quite a daunting task; for this purpose, machine learning frameworks like Tensorflow and PyTorch offer built-in support for easily accessing some of the most common datasets. In this post, I thought it’d be nice to share some examples of utilizing the Tensorflow Dataset as well as PyTorch’s torchvision dataset, which I found useful whenever I wanted a quick start on my machine learning projects.","mainEntityOfPage":{"@type":"WebPage","@id":"https://jiajiunn.github.io/posts/datasets/"},"@type":"BlogPosting","url":"https://jiajiunn.github.io/posts/datasets/","author":{"@type":"Person","name":"Jia Jiunn Ang"},"@context":"https://schema.org"}</script> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Jia Jiunn Ang</a></div><div class="site-subtitle font-italic">Cornell University junior<br>studying CS & Statistics.</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <span id="mode-toggle-wrapper"> <!-- Switch the mode between dark and light. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <i class="mode-toggle fas fa-sun" dark-mode-invisible></i> <i class="mode-toggle fas fa-moon" light-mode-invisible></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.mode != null) { if (this.mode == ModeToggle.DARK_MODE) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.mode != null) { if (self.mode == ModeToggle.DARK_MODE) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightkMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightkMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span> <span class="icon-border"></span> <a href=" javascript:window.open('mailto:' + ['ja497','cornell.edu'].join('@'))" > <i class="fas fa-envelope"></i> </a> <a href="https://www.linkedin.com/in/angjiajiunn/" target="_blank"> <i class="fab fa-linkedin"></i> </a> <a href="https://www.facebook.com/angjiajiunn/" target="_blank"> <i class="fab fa-facebook-f"></i> </a> <a href="https://github.com/JiaJiunn" target="_blank"> <i class="fab fa-github-alt"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Tensorflow and Pytorch Torchvision Datasets</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Tensorflow and Pytorch Torchvision Datasets</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sun, Sep 13, 2020, 12:20 AM -0400" > Sep 13 <i class="unloaded">2020-09-13T00:20:00-04:00</i> </span> by <span class="author"> Jia Jiunn Ang </span></div><div> Updated <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Tue, Sep 22, 2020, 10:15 PM -0400" > Sep 22 <i class="unloaded">2020-09-22T22:15:42-04:00</i> </span></div></div><div class="post-content"><p>An integral component of any high-performing model is the dataset; it defines the real world examples that form the basis of what a model learns. But for some, gathering a clean, well-formatted dataset while focusing on fine-tuning their network and learning parameters can be quite a daunting task; for this purpose, machine learning frameworks like Tensorflow and PyTorch offer built-in support for easily accessing some of the most common datasets. In this post, I thought it’d be nice to share some examples of utilizing the Tensorflow Dataset as well as PyTorch’s torchvision dataset, which I found useful whenever I wanted a quick start on my machine learning projects.</p><h2 id="tensorflow-dataset">Tensorflow Dataset</h2><p>The full list of TensorFlow Datasets can be found <a href="https://www.tensorflow.org/datasets/catalog/overview">here</a>. As you can tell, the list is quite extensive; I personally am interested in implementing a panoptic segmentation network at the moment, so I decided to check out the COCO 2017 panoptic dataset. I first ran a few imports:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/datasets/tf_imports.png" alt="tf imports" /></p><p>and tried loading the dataset. For me, though, I got some errors for exceeding the limit allowed for open files. I solved this error by simply increasing the soft limit for number of open files on my device:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/datasets/tf_file_lim.png" alt="tf file lim" /></p><p>and now, I finally load in the dataset:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/datasets/tf_load.png" alt="tf load" /></p><p>To be clear, the parameter <code class="language-plaintext highlighter-rouge">download</code> should be set to <code class="language-plaintext highlighter-rouge">True</code> whenever calling this function for the first time. This downloads the COCO dataset onto your local machine, in whichever directory you define; by default it should be under <code class="language-plaintext highlighter-rouge">~/tensorflow_datasets/coco/2017_panoptic/1.1.0/</code>. I also set the <code class="language-plaintext highlighter-rouge">split</code> parameter above to <code class="language-plaintext highlighter-rouge">train[10:20]</code>, since I only wanted to download a portion of the dataset. For future function calls, you can simply set <code class="language-plaintext highlighter-rouge">download=False</code> for using the dataset already downloaded on your local machine.</p><p>Now that we have the dataset in our directory, we can load in our dataset it as an iterator. This allows for lazy evaluation of each sample of the dataset (rather than storing the entire thing in memory upon initiation), which makes it more memory efficient. Whenever we want a sample of the dataset, we can simply use the default iterator’s <code class="language-plaintext highlighter-rouge">get_next()</code> method:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/datasets/tf_iter.png" alt="tf iter" /></p><p>And finally, here’s an image from our dataset!</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/datasets/tf_image.png" alt="tf image" /></p><p>From the <a href="https://www.tensorflow.org/datasets/catalog/coco">documentation</a> given on the Tensorflow COCO dataset, we can see that we have several labels we can get for each image. For instance, we can get the panoptic mask:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/datasets/tf_mask.png" alt="tf mask" /></p><p>as well as various ground truth labels such as bounding boxes and the corresponding classes:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/datasets/tf_label.png" alt="tf label" /></p><p>which can then be piped into a training or evaluation pipeline for further use.</p><h2 id="torchvision-dataset">Torchvision Dataset</h2><p>For proponents of PyTorch, the <a href="https://pytorch.org/docs/stable/torchvision/datasets.html">torchvision</a> library also has in-built support for several popular datasets. In contrast to Tensorflow, though, the number of PyTorch-supported datasets are significantly lesser, and use cases much limited. Nevertheless, it still covers most of the popularly used datasets (it also includes COCO!) and is a good place to start for any machine learning projects in PyTorch.</p><p>For some variation, I thought I’d run through a set up for the MNIST dataset, which is really popular for introductory machine learning projects (can be easily trained with simpler models like LeNet). I started off by running the imports as usual:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/datasets/pt_imports.png" alt="pt imports" /></p><p>One important detail is that the images loaded from the MNIST dataset are PIL images. This itself isn’t a problem, but for using PyTorch’s data loader, the function expects a tensor as the image input. Hence while loading in the data below, I included a transform for converting each loaded PIL image into a tensor. Note that any other transforms (such as modifying the image size, or changing it to grayscale etc.) can be done by simply adding the transform into the list of <code class="language-plaintext highlighter-rouge">transforms.Compose</code>.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/datasets/pt_download.png" alt="pt download" /></p><p>As in the Tensorflow example, the parameter <code class="language-plaintext highlighter-rouge">download</code> should be set to <code class="language-plaintext highlighter-rouge">True</code> only when using the function for the first time, which downloads the dataset into whichever directory defined by <code class="language-plaintext highlighter-rouge">root</code>. For future calls, setting <code class="language-plaintext highlighter-rouge">download=False</code> will then simply get the dataset from the <code class="language-plaintext highlighter-rouge">root</code> directory.</p><p>Now, we again load in our dataset as an iterator:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/datasets/pt_load.png" alt="pt load" /></p><p>As before, we can get the next sample using the in-built <code class="language-plaintext highlighter-rouge">next()</code> method.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/datasets/pt_iter.png" alt="pt iter" /></p><p>And we are done! Here is a sample image and its corresponding ground truth label, 5:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/datasets/pt_sample.png" alt="pt sample" /></p><p>Hope you found this post helpful as a quick and easy start for your own machine learning projects!</p></div><div class="post-tail-wrapper text-muted"><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/datasets/" class="post-tag no-text-decoration" >datasets</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://www.facebook.com/sharer/sharer.php?title=Tensorflow and Pytorch Torchvision Datasets - Jia Jiunn Ang&u=https://jiajiunn.github.io/posts/datasets/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://twitter.com/intent/tweet?text=Tensorflow and Pytorch Torchvision Datasets - Jia Jiunn Ang&url=https://jiajiunn.github.io/posts/datasets/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://telegram.me/share?text=Tensorflow and Pytorch Torchvision Datasets - Jia Jiunn Ang&url=https://jiajiunn.github.io/posts/datasets/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Pannel on right side (Desktop views) v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/phosa/">Improving 3D Human-Object Spatial Arrangement Predictions using Affordance -- Project Ideas</a></li><li><a href="/posts/datasets/">Tensorflow and Pytorch Torchvision Datasets</a></li><li><a href="/posts/pipeline/">Software Structure for a Machine Learning Pipeline in PyTorch</a></li><li><a href="/posts/yolo/">Implementing YOLOv3 in Tensorflow</a></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/mask-rcnn/">mask rcnn</a> <a class="post-tag" href="/tags/yolo/">yolo</a> <a class="post-tag" href="/tags/pose-estimation/">pose estimation</a> <a class="post-tag" href="/tags/pipeline/">pipeline</a> <a class="post-tag" href="/tags/datasets/">datasets</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/phosa/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Sep 22 <i class="unloaded">2020-09-22T21:08:00-04:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Improving 3D Human-Object Spatial Arrangement Predictions using Affordance -- Project Ideas</h3><div class="text-muted small"><p> Recently I’ve been quite intrigued by the area of pose estimation, and read quite a few papers on the subject. I thought I’d take this opportunity to share some of what I learned. I was particularl...</p></div></div></a></div><div class="card"> <a href="/posts/pipeline/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Sep 11 <i class="unloaded">2020-09-11T02:01:00-04:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Software Structure for a Machine Learning Pipeline in PyTorch</h3><div class="text-muted small"><p> Recently, I’ve been working on designing an end-to-end machine learning model pipeline for a project I am involved in. I just thought I’d share some of my high-level designs here, as a way of summa...</p></div></div></a></div><div class="card"> <a href="/posts/mask-rcnn-1/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Aug 30 <i class="unloaded">2020-08-30T21:35:00-04:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Mask R-CNN in Keras, Part 1&#58; Backbone and RPN</h3><div class="text-muted small"><p> In my previous post, I went through a somewhat high level overview of the R-CNN family, which personally gave me a fairly intuitive idea of each of Mask R-CNN’s components. Nevertheless, to get a d...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/pipeline/" class="btn btn-outline-primary"><p>Software Structure for a Machine Learning Pipeline in PyTorch</p></a> <a href="/posts/phosa/" class="btn btn-outline-primary"><p>Improving 3D Human-Object Spatial Arrangement Predictions using Affordance -- Project Ideas</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script> <!-- The Footer v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2020 <a href="https://github.com/JiaJiunn">Jia Jiunn Ang</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy/">Chirpy</a> theme.</p></div></div></footer></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/mask-rcnn/">mask rcnn</a> <a class="post-tag" href="/tags/yolo/">yolo</a> <a class="post-tag" href="/tags/pose-estimation/">pose estimation</a> <a class="post-tag" href="/tags/pipeline/">pipeline</a> <a class="post-tag" href="/tags/datasets/">datasets</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', '', 'auto'); ga('send', 'pageview'); </script> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://jiajiunn.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
