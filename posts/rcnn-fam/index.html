<!DOCTYPE html><html lang="en" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>A (Really) Brief Overview of the RCNN Family | Jia Jiunn Ang</title><meta name="generator" content="Jekyll v4.1.1" /><meta property="og:title" content="A (Really) Brief Overview of the RCNN Family" /><meta name="author" content="Jia Jiunn Ang" /><meta property="og:locale" content="en_US" /><meta name="description" content="Lately I’ve been reading up on Mask-RCNN and figuring out how to best implement it, but in the process, I realized that going through the development history of the RCNN family actually gives a fairly intuitive introduction to how the Mask-RCNN structure came to be. This post is by no means an in-depth explanation of how to implement each model — rather, I thought I’d take this chance to go over the highlights of each member of the RCNN family, and hopefully give intuition on how their components slowly evolved and improved into Mask-RCNN, which is a popular solution today for the panoptic segmentation problem. For a more detailed explanation, here are some helpful links: [1] and [2]." /><meta property="og:description" content="Lately I’ve been reading up on Mask-RCNN and figuring out how to best implement it, but in the process, I realized that going through the development history of the RCNN family actually gives a fairly intuitive introduction to how the Mask-RCNN structure came to be. This post is by no means an in-depth explanation of how to implement each model — rather, I thought I’d take this chance to go over the highlights of each member of the RCNN family, and hopefully give intuition on how their components slowly evolved and improved into Mask-RCNN, which is a popular solution today for the panoptic segmentation problem. For a more detailed explanation, here are some helpful links: [1] and [2]." /><link rel="canonical" href="https://jiajiunn.github.io/posts/rcnn-fam/" /><meta property="og:url" content="https://jiajiunn.github.io/posts/rcnn-fam/" /><meta property="og:site_name" content="Jia Jiunn Ang" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-08-29T13:09:00-04:00" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"headline":"A (Really) Brief Overview of the RCNN Family","dateModified":"2020-08-29T13:09:00-04:00","datePublished":"2020-08-29T13:09:00-04:00","description":"Lately I’ve been reading up on Mask-RCNN and figuring out how to best implement it, but in the process, I realized that going through the development history of the RCNN family actually gives a fairly intuitive introduction to how the Mask-RCNN structure came to be. This post is by no means an in-depth explanation of how to implement each model — rather, I thought I’d take this chance to go over the highlights of each member of the RCNN family, and hopefully give intuition on how their components slowly evolved and improved into Mask-RCNN, which is a popular solution today for the panoptic segmentation problem. For a more detailed explanation, here are some helpful links: [1] and [2].","mainEntityOfPage":{"@type":"WebPage","@id":"https://jiajiunn.github.io/posts/rcnn-fam/"},"@type":"BlogPosting","url":"https://jiajiunn.github.io/posts/rcnn-fam/","author":{"@type":"Person","name":"Jia Jiunn Ang"},"@context":"https://schema.org"}</script> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"> <!-- CSS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/css/lib/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/css/lib/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" async></script> <!-- JS selector for site. Chirpy v2.3 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT Licensed --> <script src="/assets/js/post.min.js" async></script> <script src="/app.js" defer></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="profile-text mt-3"><div class="site-title"> <a href="/">Jia Jiunn Ang</a></div><div class="site-subtitle font-italic">Cornell University junior<br>studying CS & Statistics.</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <span id="mode-toggle-wrapper"> <!-- Switch the mode between dark and light. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <i class="mode-toggle fas fa-sun" dark-mode-invisible></i> <i class="mode-toggle fas fa-moon" light-mode-invisible></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.mode != null) { if (this.mode == ModeToggle.DARK_MODE) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.mode != null) { if (self.mode == ModeToggle.DARK_MODE) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightkMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightkMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span> <span class="icon-border"></span> <a href=" javascript:window.open('mailto:' + ['ja497','cornell.edu'].join('@'))" > <i class="fas fa-envelope"></i> </a> <a href="https://www.linkedin.com/in/angjiajiunn/" target="_blank"> <i class="fab fa-linkedin"></i> </a> <a href="https://www.facebook.com/angjiajiunn/" target="_blank"> <i class="fab fa-facebook-f"></i> </a> <a href="https://github.com/JiaJiunn" target="_blank"> <i class="fab fa-github-alt"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>A (Really) Brief Overview of the RCNN Family</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Refactor the HTML structure. --> <!-- Suroundding the markdown table with '<div class="table-wrapper">. and '</div>' --> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>A (Really) Brief Overview of the RCNN Family</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Sat, Aug 29, 2020, 1:09 PM -0400" > Aug 29 <i class="unloaded">2020-08-29T13:09:00-04:00</i> </span> by <span class="author"> Jia Jiunn Ang </span></div></div><div class="post-content"><p>Lately I’ve been reading up on Mask-RCNN and figuring out how to best implement it, but in the process, I realized that going through the development history of the RCNN family actually gives a fairly intuitive introduction to how the Mask-RCNN structure came to be. This post is by no means an in-depth explanation of how to implement each model — rather, I thought I’d take this chance to go over the highlights of each member of the RCNN family, and hopefully give intuition on how their components slowly evolved and improved into Mask-RCNN, which is a popular solution today for the panoptic segmentation problem. For a more detailed explanation, here are some helpful links: <a href="https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e">[1]</a> and <a href="https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4">[2]</a>.</p><h2 id="r-cnn">R-CNN</h2><p>Some time ago, a team at UC Berkeley addressed the question: given an image, how do we output bounding boxes around objects in the image, along with their corresponding classes?</p><p>At the time, SVMs were a known tool for classifying images, and is still currently quite a popular algorithm for classifying the MNIST dataset in many introduction-to-ML Medium articles. Using this, the team came up with a fairly intuitive solution: generate a bunch of region proposals, then pipe them into an SVM classifier to get the class of potential objects in these proposed regions. It additionally runs a linear regression model after the classes are generated, to tighten the bounding boxes on objects of the respective classes. They called this model the R-CNN, and published a <a href="https://arxiv.org/pdf/1311.2524.pdf">paper</a> on it.</p><h2 id="fast-r-cnn">Fast R-CNN</h2><p>After publishing their RCNN paper, the authors sat back, and realized that the model they designed had a major bottleneck: it was taking a ton (~2000) of sub-regions of the same image, most of which overlap, and passing them through a convolutional network. This led to a lot of redundant, as well as time-consuming work — 2000 convolutions take quite some time after all, around 47 seconds — so why can’t they first run convolutions on the entire image, then get region proposals from the feature maps? That’s exactly what they did, which drastically reduced the run time. They then used a technique called ROIPooling to warp the images into a fixed size, then piped the output to a softmax layer and linear regression layer separately. Here’s a nice visual from their paper:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/rcnn_fam/fast_rcnn_paper.png" alt="Fast R-CNN" /></p><p>Notice that there is another factor at play here that improves the R-CNN model; previously, R-CNN was comprised of three separate networks: the CNN (for extracting features), the SVM (for identifying object class), and the linear regressor (for tightening the generated bounding boxes). This makes the network somewhat complicated to train - but now, the entire framework is unified under one pipeline, since the SVM is replaced by a simple softmax layer added on top of the CNN, while the linear regression layer is just added as an additional layer parallel to the softmax layer. This way, training can be done in a much simpler fashion, possibly achieving lower accuracy too. The authors call this model <a href="https://arxiv.org/pdf/1504.08083.pdf">Fast R-CNN</a>.</p><p>Notice that at this point, inference time has been brought down to 2.3 seconds; however, from this graphic I stole from (credits to) <a href="https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e">this Medium article</a>:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/rcnn_fam/fast_rcnn_time.png" alt="Fast R-CNN time" /></p><p>we can see that the region proposals have now become the bottlenecks for the model inference, slowing performance down by more than seven-fold.</p><h2 id="faster-r-cnn">Faster R-CNN</h2><p>You may now be curious: how did we actually generate region proposals since the very beginning? Well, for both R-CNN and Fast R-CNN, we have been using a method called selective search, which essentially generates a bunch of sub-segmentations, then greedily combine similar regions before outputting them. However, this algorithm is not only time-consuming, but also can’t really be optimized much since it doesn’t have parameters to learn. As such, a team at Microsoft Research replaced it with another neural network, which seems to solve most of our problems these days (neural networks are essentially giant approximation algorithms anyway). They called this network the Region Proposal Network (RPN), which, as you can guess, predicts region proposals. The outputs are then reshaped to a fixed size using ROIPooling, and the rest of the network is similar to that of Fast R-CNN’s. Following the naming pattern, they called their improved model <a href="https://arxiv.org/pdf/1506.01497.pdf">Faster R-CNN</a>, since it was, indeed, much faster. Graphics credits yet again from <a href="https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e">the same Medium article</a>.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/rcnn_fam/faster_rcnn_time.png" alt="Faster R-CNN time" /></p><h2 id="mask-r-cnn">Mask R-CNN</h2><p>More recently, a team at Facebook AI Research wondered if they could expand upon this network to generate panoptic masks. Well, you may think, the RPN currently outputs a bunch of region proposals, right? So in addition to sending these regions for classification and drawing bounding boxes and such, can we just send the same regions to another FCN for predicting masks?</p><p>If that is indeed what you are thinking, then yes, that’s exactly what those researchers did. They added a branch extending from Fast R-CNN’s RPN, which passes through a standard <code class="language-plaintext highlighter-rouge">CNN + FCN</code> combo to output a binary mask, where each pixel is classified if it is part of a particular instance of an object. Intuitive, right?</p><p>Here’s a visual from their <a href="https://arxiv.org/pdf/1703.06870.pdf">paper</a>, which extends from Faster R-CNN with a ResNet backbone:</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/rcnn_fam/mask_rcnn_paper.png" alt="Mask R-CNN" /></p><p>There is just one last detail to cover; the original region proposals obtained from ROIPool are, as the name suggests, pooled, so there exists a loss of pixel-level precision when we try to map the predicted mask to the original image’s pixel. You can somewhat envision the problem from this example: the 15th pixel of a 128 x 128 image, when pooled down to size 25 x 25, would correspond to the 2.93rd pixel. But since we want to classify each pixel in the original image, the rounding from ROIPool obviously poses a problem.</p><p>In response to this, the Facebook researchers came up with ROIAlign: the idea is that instead of rounding our floating points to ints during ROIPool, we apply bilinear interpolation to figure out what values are present in each feature map grid. In essence, we preserve the precision of each pixel-level correspondence, preventing any misalignments between the feature maps and the original image.</p><h2 id="remarks">Remarks</h2><p>And that’s about it! Hopefully that provided you with some insight as to why each component of Mask R-CNN is arranged the way it is – we put the convolution block first because if it were the other way round, the repeated convolutions would slow down the entire model; the RPN is meant as a substitute for the intuitive act of generating potential regions, and the classifier and bounding boxes are attached to the end of our network for a more unified training process, etc.</p></div><div class="post-tail-wrapper text-muted"><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/mask-rcnn/" class="post-tag no-text-decoration" >mask-rcnn</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://www.facebook.com/sharer/sharer.php?title=A (Really) Brief Overview of the RCNN Family - Jia Jiunn Ang&u=https://jiajiunn.github.io/posts/rcnn-fam/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://twitter.com/intent/tweet?text=A (Really) Brief Overview of the RCNN Family - Jia Jiunn Ang&url=https://jiajiunn.github.io/posts/rcnn-fam/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://telegram.me/share?text=A (Really) Brief Overview of the RCNN Family - Jia Jiunn Ang&url=https://jiajiunn.github.io/posts/rcnn-fam/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Pannel on right side (Desktop views) v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/phosa/">Improving 3D Human-Object Spatial Arrangement Predictions using Affordance -- Project Ideas</a></li><li><a href="/posts/datasets/">Tensorflow and Pytorch Torchvision Datasets</a></li><li><a href="/posts/pipeline/">Software Structure for a Machine Learning Pipeline in PyTorch</a></li><li><a href="/posts/yolo/">Implementing YOLOv3 in Tensorflow</a></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/mask-rcnn/">mask rcnn</a> <a class="post-tag" href="/tags/yolo/">yolo</a> <a class="post-tag" href="/tags/pose-estimation/">pose estimation</a> <a class="post-tag" href="/tags/pipeline/">pipeline</a> <a class="post-tag" href="/tags/datasets/">datasets</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-2">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Recommend the other 3 posts according to the tags and categories of the current post, if the number is not enough, use the other latest posts to supplement. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/mask-rcnn-1/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Aug 30 <i class="unloaded">2020-08-30T21:35:00-04:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Mask R-CNN in Keras, Part 1&#58; Backbone and RPN</h3><div class="text-muted small"><p> In my previous post, I went through a somewhat high level overview of the R-CNN family, which personally gave me a fairly intuitive idea of each of Mask R-CNN’s components. Nevertheless, to get a d...</p></div></div></a></div><div class="card"> <a href="/posts/phosa/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Sep 22 <i class="unloaded">2020-09-22T21:08:00-04:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Improving 3D Human-Object Spatial Arrangement Predictions using Affordance -- Project Ideas</h3><div class="text-muted small"><p> Recently I’ve been quite intrigued by the area of pose estimation, and read quite a few papers on the subject. I thought I’d take this opportunity to share some of what I learned. I was particularl...</p></div></div></a></div><div class="card"> <a href="/posts/datasets/"><div class="card-body"> <!-- Date format snippet v2.4.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --> <span class="timeago small" > Sep 13 <i class="unloaded">2020-09-13T00:20:00-04:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Tensorflow and Pytorch Torchvision Datasets</h3><div class="text-muted small"><p> An integral component of any high-performing model is the dataset; it defines the real world examples that form the basis of what a model learns. But for some, gathering a clean, well-formatted dat...</p></div></div></a></div></div></div><!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <a href="/posts/yolo/" class="btn btn-outline-primary"><p>Implementing YOLOv3 in Tensorflow</p></a> <a href="/posts/mask-rcnn-1/" class="btn btn-outline-primary"><p>Mask R-CNN in Keras, Part 1&#58; Backbone and RPN</p></a></div></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('#post-wrapper img'); const observer = lozad(imgs); observer.observe(); </script> <!-- The Footer v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2020 <a href="https://github.com/JiaJiunn">Jia Jiunn Ang</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy/">Chirpy</a> theme.</p></div></div></footer></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/mask-rcnn/">mask rcnn</a> <a class="post-tag" href="/tags/yolo/">yolo</a> <a class="post-tag" href="/tags/pose-estimation/">pose estimation</a> <a class="post-tag" href="/tags/pipeline/">pipeline</a> <a class="post-tag" href="/tags/datasets/">datasets</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', '', 'auto'); ga('send', 'pageview'); </script> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://jiajiunn.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
